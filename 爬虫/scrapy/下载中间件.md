# 下载中间件
#爬虫/Scrapy

Minddlewares
实现两个方法：  
::process_request(self, requests, spider)::
	1. 参数：
		1. request ： 发送请求的对象
		2. spider：发送请求的 spider 对象
	2. 返回值
		1. None， Scrapy 继续请求request 
		2. Response对象，Scrapy不会调用process_request方法
		3. Request对象，发送给下一个中间件处理
		4. 如果抛出异常，调用 process_expception
::process_response(self, request, response ,spider)::
	1. 参数：
		1. request
		2. response，下载的数据
		3. spider
	2. 返回值
		1. Response对象，
		2. Requests对象，返回到下载器进行处理
		3. 异常 requests 的 errback 方法
	
![](%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6/729EA8CF-E1E6-4FBE-A83C-7C24D687262F.png)

## 设置随机请求头
User-Agent
[UserAgentString.com - List of Browser User Agent Strings](http://www.useragentstring.com/pages/useragentstring.php?typ=Browser)
![](%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6/1C8AD962-36AE-46ED-9123-092C36515B2F.png)


## IP代理池
快代理

### 开放代理
![](%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6/DFE688B1-2E33-44B5-AA1F-91CC18BB25D5.png)

### 独享代理
![](%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6/1AB3B05D-4240-4117-8020-9CF8FAAF88BA.png)

