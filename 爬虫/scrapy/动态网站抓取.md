# 动态网站抓取
#爬虫/Scrapy

## selenium
web 应用程序测试::工具::

![](%E5%8A%A8%E6%80%81%E7%BD%91%E7%AB%99%E6%8A%93%E5%8F%96/AC826A7F-77B9-4562-9B4B-B655CEAFAD3F.png)

安装驱动程序 driver
[selenium Python api](https://selenium-python-zh.readthedocs.io/en/latest/api.html)

## 使用
Chrome(executable_path=“driver 文件路径”)
![](%E5%8A%A8%E6%80%81%E7%BD%91%E7%AB%99%E6%8A%93%E5%8F%96/06A91EF6-14BB-4D38-9F24-0BED3796FB77.png)
browser.quit()

## 鼠标下滑
::browser.execute_scrapt(‘window.scrollTo(0, document.body.scrollHeight); return lenof’)::

## 不加载图片
```python
chrome_opt = webdriver.ChromeOptions()
prefs = {
	profile.mananged_default_content_settings.images”:2
}
chrome_opt.add_experimental_option(‘prefs’, prefs)
browser = webdriver.Chrome(executable_path=‘’, chrome_options = chrome_opt)
browser.get(url)
```

## phantomjs 
::无界面的浏览器:: 多进程 性能下降严重

[PhantomJS - Scriptable Headless Browser](https://phantomjs.org/)

执行文件路径替换 ::executable_path:: , 及时退出

# 集成
selenium -> scrapy (设置一个中间件)

```python
from scrapy.http import HtmlResponse

class JSPageMinddleware(object):

	def __init__(self):
		# 创建 Chrome 对象
		self.browser = (////)
		super(JSPageMiddleware, self).__init__()

	def process_request(self , request , spider):
		# 部分进行使用
		if spider.name == 'jobbole’:

			# get 请求 页面
			# time.sleep(2)
			# 不下载 
			return HtmlResponse(url= browser.current_url, body =browser.page_source, encoding=‘utf8’， request=request)

```

setting中设置 

## 多个Chrome 
将Chrome对象放到spider中

## 信号
```python
from scrapy.xlib.pydispatch import dispatcher 分发器
from sceapy import signals


def __init__(self):
		# 创建 Chrome 对象
		self.browser = (////)
		super(JSPageMiddleware, slef).__init__()
		dispatcher.conntect(self.spider_closed, signals.spider_closed)
		
def spider_closed (self , spider):
	# 信号处理函数
	self.browser.close()
```

## 其他
Python 提供了无界面的Chrome环境

::pyvirtualdisplay:: 库  linux 下

```python
from py.. import Display

desplay = Display(visible=0, size=(800,600))
display.start()
	# 创建 chrome对象
	# 获取网页信息
```

### 其他解决方案

stackoverflow

* ::sudo apt-get install svfb::
* ::pip install xvfbwrapper::

### scrapy splash

::自己运行server 运行 JavaScrapy::
支持分布式

### selenium  grid

	`也支持分布式` 

### splinter
	`操控浏览器的方案`




## 信号
![](%E5%8A%A8%E6%80%81%E7%BD%91%E7%AB%99%E6%8A%93%E5%8F%96/D48ACF1D-424C-4B4C-B47B-D6E74B4F571A.png)













